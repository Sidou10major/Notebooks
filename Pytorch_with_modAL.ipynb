{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch\n",
        "!pip install git+https://github.com/modAL-python/modAL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "Tn3tZD_BZIaG",
        "outputId": "9f949af1-2a40-429b-aba2-3fb2bcda6932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n",
            "Collecting git+https://github.com/modAL-python/modAL.git\n",
            "  Cloning https://github.com/modAL-python/modAL.git to /tmp/pip-req-build-vwmjlevx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modAL-python/modAL.git /tmp/pip-req-build-vwmjlevx\n",
            "  Resolved https://github.com/modAL-python/modAL.git to commit bba6f6fd00dbb862b1e09259b78caf6cffa2e755\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.11.3)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python==0.4.2) (1.5.3)\n",
            "Collecting skorch==0.9.0 (from modAL-python==0.4.2)\n",
            "  Downloading skorch-0.9.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python==0.4.2) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python==0.4.2) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->modAL-python==0.4.2) (1.16.0)\n",
            "Building wheels for collected packages: modAL-python\n",
            "  Building wheel for modAL-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modAL-python: filename=modAL_python-0.4.2-py3-none-any.whl size=32650 sha256=cf16c3c42e3433774c07bcdb25c0afb46b9a93bb23f8be631c835f1ad0dd1557\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2_cp36k/wheels/d9/fb/59/7deb61b460c1c36394cd093758986ff7d36f71352dcb2e02c5\n",
            "Successfully built modAL-python\n",
            "Installing collected packages: skorch, modAL-python\n",
            "  Attempting uninstall: skorch\n",
            "    Found existing installation: skorch 0.15.0\n",
            "    Uninstalling skorch-0.15.0:\n",
            "      Successfully uninstalled skorch-0.15.0\n",
            "Successfully installed modAL-python-0.4.2 skorch-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "skorch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IxJo4grIa5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "# build class for the skorch API\n",
        "class Torch_Model(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(Torch_Model, self).__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "                                nn.Conv2d(1,32,3),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Conv2d(32,64,3),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2),\n",
        "                                nn.Dropout(0.25)\n",
        "        )\n",
        "        self.fcs = nn.Sequential(\n",
        "                                nn.Linear(12*12*64,128),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(0.5),\n",
        "                                nn.Linear(128,10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.convs(out)\n",
        "        out = out.view(-1,12*12*64)\n",
        "        out = self.fcs(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the classifier\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "classifier = NeuralNetClassifier(Torch_Model,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 train_split=None,\n",
        "                                 verbose=1,\n",
        "                                 device=device)"
      ],
      "metadata": {
        "id": "RfUWmpn3Yej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "\n",
        "mnist_data = MNIST('.', download=True, transform=ToTensor())\n",
        "dataloader = DataLoader(mnist_data, shuffle=True, batch_size=60000)\n",
        "X, y = next(iter(dataloader))\n",
        "\n",
        "# read training data\n",
        "X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
        "X_train = X_train.reshape(50000, 1, 28, 28)\n",
        "X_test = X_test.reshape(10000, 1, 28, 28)\n",
        "\n",
        "# assemble initial data\n",
        "n_initial = 1000\n",
        "initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
        "X_initial = X_train[initial_idx]\n",
        "y_initial = y_train[initial_idx]\n",
        "\n",
        "# generate the pool\n",
        "# remove the initial data from the training dataset\n",
        "X_pool = np.delete(X_train, initial_idx, axis=0)[:5000]\n",
        "y_pool = np.delete(y_train, initial_idx, axis=0)[:5000]"
      ],
      "metadata": {
        "id": "ZAv1wNmzYkLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modAL.models import ActiveLearner\n",
        "\n",
        "# initialize ActiveLearner\n",
        "learner = ActiveLearner(\n",
        "    estimator=classifier,\n",
        "    X_training=X_initial, y_training=y_initial,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUbtmXn7Y1sy",
        "outputId": "986aad01-3781-4eef-9565-eaa2f4bca2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.4760\u001b[0m  2.4251\n",
            "      2        \u001b[36m2.3063\u001b[0m  2.0536\n",
            "      3        \u001b[36m2.3036\u001b[0m  4.6801\n",
            "      4        \u001b[36m2.3020\u001b[0m  4.6826\n",
            "      5        \u001b[36m2.3003\u001b[0m  3.6384\n",
            "      6        \u001b[36m2.2994\u001b[0m  6.3140\n",
            "      7        \u001b[36m2.2981\u001b[0m  2.1004\n",
            "      8        2.2990  1.9690\n",
            "      9        2.3004  1.9457\n",
            "     10        2.2988  2.5454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the active learning loop\n",
        "n_queries = 10\n",
        "for idx in range(n_queries):\n",
        "    print('Query no. %d' % (idx + 1))\n",
        "    query_idx, query_instance = learner.query(X_pool, n_instances=100)\n",
        "    learner.teach(\n",
        "        X=X_pool[query_idx], y=y_pool[query_idx], only_new=True,\n",
        "    )\n",
        "    # remove queried instance from pool\n",
        "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "    y_pool = np.delete(y_pool, query_idx, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F3sXhWdY2ba",
        "outputId": "d0b4eb1b-3bba-4649-90e2-de70d6afa5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query no. 1\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3075\u001b[0m  0.2438\n",
            "      2        5.0375  0.2403\n",
            "      3        2.6199  0.2367\n",
            "      4        \u001b[36m2.2818\u001b[0m  0.2382\n",
            "      5        \u001b[36m2.2579\u001b[0m  0.2053\n",
            "      6        \u001b[36m2.1474\u001b[0m  0.2012\n",
            "      7        \u001b[36m2.0206\u001b[0m  0.1988\n",
            "      8        \u001b[36m1.7814\u001b[0m  0.2072\n",
            "      9        \u001b[36m1.6168\u001b[0m  0.2024\n",
            "     10        \u001b[36m1.3738\u001b[0m  0.2157\n",
            "Query no. 2\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2824\u001b[0m  0.2554\n",
            "      2       20.2135  0.2354\n",
            "      3        5.2120  0.2301\n",
            "      4        \u001b[36m2.2709\u001b[0m  0.2212\n",
            "      5        \u001b[36m2.2671\u001b[0m  0.2298\n",
            "      6        \u001b[36m2.2632\u001b[0m  0.3001\n",
            "      7        \u001b[36m2.2582\u001b[0m  0.3777\n",
            "      8        \u001b[36m2.2483\u001b[0m  0.3771\n",
            "      9        \u001b[36m2.2390\u001b[0m  0.3527\n",
            "     10        \u001b[36m2.2290\u001b[0m  0.3407\n",
            "Query no. 3\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2967\u001b[0m  0.2262\n",
            "      2        5.9597  0.2076\n",
            "      3        3.4015  0.2006\n",
            "      4        \u001b[36m2.2242\u001b[0m  0.1992\n",
            "      5        \u001b[36m2.1151\u001b[0m  0.2083\n",
            "      6        \u001b[36m1.7477\u001b[0m  0.2184\n",
            "      7        \u001b[36m1.3261\u001b[0m  0.2477\n",
            "      8        \u001b[36m1.0057\u001b[0m  0.2254\n",
            "      9        \u001b[36m0.9063\u001b[0m  0.2354\n",
            "     10        \u001b[36m0.6738\u001b[0m  0.2392\n",
            "Query no. 4\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3105\u001b[0m  0.2134\n",
            "      2       19.8934  0.2067\n",
            "      3        3.0574  0.2014\n",
            "      4        2.3144  0.2058\n",
            "      5        \u001b[36m2.3087\u001b[0m  0.1995\n",
            "      6        \u001b[36m2.3056\u001b[0m  0.1934\n",
            "      7        \u001b[36m2.3008\u001b[0m  0.2392\n",
            "      8        \u001b[36m2.2959\u001b[0m  0.3465\n",
            "      9        \u001b[36m2.2891\u001b[0m  0.3375\n",
            "     10        \u001b[36m2.2849\u001b[0m  0.3343\n",
            "Query no. 5\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2997\u001b[0m  0.2086\n",
            "      2        9.3651  0.2112\n",
            "      3        3.5485  0.2462\n",
            "      4        2.3328  0.2282\n",
            "      5        2.3058  0.2337\n",
            "      6        2.3055  0.2223\n",
            "      7        2.3055  0.2408\n",
            "      8        \u001b[36m2.2986\u001b[0m  0.2229\n",
            "      9        \u001b[36m2.2849\u001b[0m  0.2362\n",
            "     10        \u001b[36m2.2658\u001b[0m  0.2239\n",
            "Query no. 6\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3232\u001b[0m  0.2262\n",
            "      2        3.7077  0.2044\n",
            "      3        4.0100  0.2016\n",
            "      4        \u001b[36m2.1687\u001b[0m  0.1967\n",
            "      5        2.2244  0.2003\n",
            "      6        2.1697  0.2045\n",
            "      7        \u001b[36m1.9902\u001b[0m  0.1986\n",
            "      8        \u001b[36m1.5558\u001b[0m  0.2094\n",
            "      9        \u001b[36m1.0986\u001b[0m  0.1951\n",
            "     10        1.1500  0.2020\n",
            "Query no. 7\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3138\u001b[0m  0.2161\n",
            "      2        5.9300  0.2037\n",
            "      3        \u001b[36m1.1533\u001b[0m  0.2004\n",
            "      4        \u001b[36m0.9304\u001b[0m  0.1944\n",
            "      5        \u001b[36m0.4890\u001b[0m  0.1957\n",
            "      6        \u001b[36m0.2987\u001b[0m  0.2103\n",
            "      7        0.3148  0.2002\n",
            "      8        \u001b[36m0.2732\u001b[0m  0.2005\n",
            "      9        \u001b[36m0.1592\u001b[0m  0.1943\n",
            "     10        \u001b[36m0.0865\u001b[0m  0.1990\n",
            "Query no. 8\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3228\u001b[0m  0.2045\n",
            "      2        2.6791  0.1955\n",
            "      3        2.3764  0.1939\n",
            "      4        \u001b[36m2.1683\u001b[0m  0.2005\n",
            "      5        \u001b[36m2.0443\u001b[0m  0.2013\n",
            "      6        \u001b[36m1.7326\u001b[0m  0.1978\n",
            "      7        \u001b[36m1.6917\u001b[0m  0.1961\n",
            "      8        \u001b[36m1.6005\u001b[0m  0.1965\n",
            "      9        \u001b[36m1.3412\u001b[0m  0.2049\n",
            "     10        \u001b[36m1.1057\u001b[0m  0.2323\n",
            "Query no. 9\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3862\u001b[0m  0.3641\n",
            "      2        \u001b[36m0.0000\u001b[0m  0.2685\n",
            "      3        \u001b[36m0.0000\u001b[0m  0.5035\n",
            "      4        0.0000  0.3431\n",
            "      5        0.0000  0.2036\n",
            "      6        0.0000  0.2079\n",
            "      7        0.0000  0.2298\n",
            "      8        0.0000  0.2415\n",
            "      9        0.0000  0.2369\n",
            "     10        0.0000  0.2291\n",
            "Query no. 10\n",
            "Re-initializing module.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2885\u001b[0m  0.2505\n",
            "      2        9.0220  0.2243\n",
            "      3        3.2402  0.2246\n",
            "      4        2.2992  0.2192\n",
            "      5        \u001b[36m2.2504\u001b[0m  0.2215\n",
            "      6        \u001b[36m2.1685\u001b[0m  0.2259\n",
            "      7        \u001b[36m2.0248\u001b[0m  0.2160\n",
            "      8        \u001b[36m1.9048\u001b[0m  0.2219\n",
            "      9        \u001b[36m1.7080\u001b[0m  0.2182\n",
            "     10        \u001b[36m1.5149\u001b[0m  0.2248\n"
          ]
        }
      ]
    }
  ]
}